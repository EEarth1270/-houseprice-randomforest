{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,VotingRegressor,StackingRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression, BayesianRidge,ElasticNet,ARDRegression,HuberRegressor,SGDRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import iqr\n",
    "from pandas.api.types import CategoricalDtype \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_no_nans = []\n",
    "for col in train_dataset.columns:\n",
    "  if not train_dataset[col].isnull().any():\n",
    "    if col != 'SalePrice':\n",
    "      cols_with_no_nans.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "salePrice = train_dataset['SalePrice']\n",
    "train_dataset= train_dataset[cols_with_no_nans]\n",
    "test_dataset = pd.read_csv('../data/test.csv')\n",
    "test_dataset= test_dataset[cols_with_no_nans]\n",
    "dataset =  train_dataset.append(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = oneHotEncode(dataset,cols_with_no_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[:1460]\n",
    "test_dataset = dataset[1460:]\n",
    "train_dataset = pd.concat([train_dataset,salePrice],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_List =['LotArea','GrLivArea','GarageArea']\n",
    "# for col in train_dataset.columns:\n",
    "#   if(col in in_List):\n",
    "#     a =iqr(train_dataset[col])*1.5\n",
    "#     Q75 = train_dataset[col].quantile(0.75) +a\n",
    "#     Q25 = train_dataset[col].quantile(0.25) -a\n",
    "#     train_dataset = train_dataset[train_dataset[col]<Q75]\n",
    "#     if Q25 < 0:\n",
    "#       Q25=0\n",
    "#       train_dataset = train_dataset[train_dataset[col]>Q25]\n",
    "#     print(col,a,Q75,Q25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(train_dataset['lognorm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset['LotArea'] = np.log10(train_dataset['LotArea'])\n",
    "# train_dataset['GrLivArea'] = np.log10(train_dataset['GrLivArea'])\n",
    "# train_dataset['GarageArea'] = np.log10(train_dataset['GarageArea'])\n",
    "train_dataset['lognorm'] = np.log10(train_dataset['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset['lognorm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(train_dataset['lognorm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds, test_ds  = train_test_split(train_dataset,test_size=0.2,random_state=1)\n",
    "train_ds = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyteruser/.local/lib/python3.8/site-packages/pandas/core/frame.py:4316: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "test_dataset.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "esti  = [('huber',HuberRegressor(epsilon=1.25)),('lr',LinearRegression()),\n",
    "         ('rf',RandomForestRegressor(n_estimators=1000,max_features=0.33, n_jobs=- 1)),\n",
    "         ('elas',ElasticNet()),\n",
    "         ('gb',GradientBoostingRegressor(n_estimators=10000,max_features=0.33,learning_rate=0.02)),\n",
    "         ('lgb',LGBMRegressor(n_estimators=10000,max_features=0.33,learning_rate=0.02, n_jobs=- 1)),\n",
    "         ('xgb',XGBRegressor(n_estimators=10000,max_features=0.33,learning_rate=0.02, n_jobs=- 1)),\n",
    "         ('ridge',Ridge(alpha=8)),('bayesridge',BayesianRidge()),('ard',ARDRegression())]\n",
    "# #         ('elas',ElasticNet())] +('lr',LinearRegression()),('huber',HuberRegressor())\n",
    "# vtreg = VotingRegressor(estimators=esti,n_jobs=-1,verbose=True)\n",
    "reg = StackingRegressor(estimators=esti,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(estimators=[('huber', HuberRegressor(epsilon=1.25)),\n",
       "                              ('lr', LinearRegression()),\n",
       "                              ('rf',\n",
       "                               RandomForestRegressor(max_features=0.33,\n",
       "                                                     n_estimators=1000,\n",
       "                                                     n_jobs=-1)),\n",
       "                              ('elas', ElasticNet()),\n",
       "                              ('gb',\n",
       "                               GradientBoostingRegressor(learning_rate=0.02,\n",
       "                                                         max_features=0.33,\n",
       "                                                         n_estimators=10000)),\n",
       "                              ('lgb',\n",
       "                               LGBMRegressor(learning_rate=0.02,\n",
       "                                             max_features=0.33,\n",
       "                                             n_estimat...\n",
       "                                            max_features=0.33,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=10000, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                              ('ridge', Ridge(alpha=8)),\n",
       "                              ('bayesridge', BayesianRidge()),\n",
       "                              ('ard', ARDRegression())],\n",
       "                  n_jobs=-1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(train_ds.iloc[:,1:-2],train_ds['lognorm'])\n",
    "# reg.fit(train_ds.iloc[:,1:-1],train_ds['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reg.predict(test_dataset.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.07541951 5.19713942 5.26096686 ... 5.19405197 5.04968579 5.36210569]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 10 ** result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118965.08112605 157448.82300098 182375.65338659 ... 156333.47065412\n",
      " 112120.69697992 230200.19695463]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=pd.DataFrame({'SalePrice':result})\n",
    "submission = pd.concat([test_dataset['Id'],ans],axis=1)\n",
    "submission.to_csv('../output_ML/wait_for_score/outputstacking12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
